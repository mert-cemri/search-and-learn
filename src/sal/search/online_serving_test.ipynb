{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRAFT_MODEL=\"Qwen/Qwen2.5-Math-1.5B-Instruct\"\n",
    "TARGET_MODEL=\"Qwen/Qwen2.5-Math-7B-Instruct\"\n",
    "PRM=\"Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B\"\n",
    "DRAFT_IP_ADDRESS=\"http://localhost:12340/v1\"\n",
    "TARGET_IP_ADDRESS=\"http://localhost:12341/v1\"\n",
    "PRM_IP_ADDRESS=\"http://localhost:12342/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mert/miniconda3/envs/spec/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "openai_api_key = \"EMPTY\"\n",
    "\n",
    "args = {\n",
    "    \"draft_model_path_rsd\": DRAFT_MODEL,\n",
    "    \"draft_model_ip_address\": DRAFT_IP_ADDRESS,\n",
    "    \"target_model_path_rsd\": TARGET_MODEL,\n",
    "    \"target_model_ip_address\": TARGET_IP_ADDRESS,\n",
    "    \"prm_ip_address_rsd\": PRM_IP_ADDRESS,\n",
    "    \"prm_path_rsd\": PRM\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_client = OpenAI(\n",
    "        api_key=openai_api_key,\n",
    "        base_url=args[\"draft_model_ip_address\"],\n",
    "    )\n",
    "draft_tokenizer = AutoTokenizer.from_pretrained(args[\"draft_model_path_rsd\"], trust_remote_code=True)\n",
    "\n",
    "target_client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=args[\"target_model_ip_address\"],\n",
    ")\n",
    "target_tokenizer = AutoTokenizer.from_pretrained(args[\"target_model_path_rsd\"], trust_remote_code=True)\n",
    "\n",
    "prm_client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=args[\"prm_ip_address_rsd\"],\n",
    ")\n",
    "prm_tokenizer = AutoTokenizer.from_pretrained(args[\"prm_path_rsd\"], trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"draft_model_name_or_path\": DRAFT_MODEL,\n",
    "    \"temperature\": 1.0,\n",
    "    \"top_p\": 0.9,\n",
    "    \"max_tokens\": 2048\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_prompts = [\n",
    "            \"Say hello\",\n",
    "            \"Say goodbye\"\n",
    "        ]\n",
    "llm = draft_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_responses = llm.completions.create(\n",
    "                model=config[\"draft_model_name_or_path\"].split(\"/\")[-1],\n",
    "                prompt=gen_prompts,\n",
    "                temperature=config[\"temperature\"],\n",
    "                top_p=config[\"top_p\"],\n",
    "                max_tokens=config[\"max_tokens\"],\n",
    "                stop=[\"\\n\\n\"],\n",
    "                n=1,\n",
    "                stream=False,\n",
    "                extra_body={\n",
    "                    \"include_stop_str_in_output\": True\n",
    "                                   }\n",
    "            ).choices\n",
    "llm_outputs = sorted(draft_responses, key=lambda x: int(x.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_outputs: \n",
      " [CompletionChoice(finish_reason='stop', index=0, logprobs=None, text='. The language model uses a simplified attention mechanism to weigh theimportance of each word in a sentence. The attention weights are calculated using a scoring function that takes into account the context and the context itself. For a given sentence, the attention weight for each word is given by the formula:\\n\\n', stop_reason='\\n\\n', prompt_logprobs=None), CompletionChoice(finish_reason='stop', index=1, logprobs=None, text=', Sumit, and submergedCities. The number of people in these three cities is given as follows:\\n- Sumit has 12,345 people.\\n- Subha has 10,987 people.\\n- Submarines have 8,765 people.\\n\\n', stop_reason='\\n\\n', prompt_logprobs=None)]\n"
     ]
    }
   ],
   "source": [
    "print(\"llm_outputs: \\n\", llm_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.text: . The language model uses a simplified attention mechanism to weigh theimportance of each word in a sentence. The attention weights are calculated using a scoring function that takes into account the context and the context itself. For a given sentence, the attention weight for each word is given by the formula:\n",
      "\n",
      "\n",
      "output.index: 0\n",
      "output.finish_reason: stop\n",
      "output.logprobs: None\n",
      "output.text: , Sumit, and submergedCities. The number of people in these three cities is given as follows:\n",
      "- Sumit has 12,345 people.\n",
      "- Subha has 10,987 people.\n",
      "- Submarines have 8,765 people.\n",
      "\n",
      "\n",
      "output.index: 1\n",
      "output.finish_reason: stop\n",
      "output.logprobs: None\n"
     ]
    }
   ],
   "source": [
    "for output in llm_outputs:\n",
    "    print(f\"output.text: {output.text}\")\n",
    "    print(f\"output.index: {output.index}\")\n",
    "    print(f\"output.finish_reason: {output.finish_reason}\")\n",
    "    print(f\"output.logprobs: {output.logprobs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(problem, response, tokenizer, step_token):\n",
    "    prompt_ids = tokenizer.encode(tokenizer.bos_token + problem + \"\\n\")\n",
    "    response_ids = []\n",
    "    steps = []\n",
    "    reward_flags = [0] * len(prompt_ids)\n",
    "    step_token_id = tokenizer.encode(step_token)[-1]\n",
    "    for idx, step in enumerate(response.split(step_token)):\n",
    "        if step != \"\":\n",
    "            step_ids = tokenizer.encode(step)\n",
    "        else:\n",
    "            step_ids = []\n",
    "        step_ids += [step_token_id]\n",
    "        step = step + step_token\n",
    "        flag = [0] * len(step_ids)\n",
    "        flag[-1] = 1\n",
    "        response_ids.extend(step_ids)\n",
    "        reward_flags.extend(flag)\n",
    "        steps.append(step)\n",
    "    input_ids = prompt_ids + response_ids\n",
    "    return input_ids, steps, reward_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = [\n",
    "    prepare_input(p, full_resp.text, tokenizer=prm_tokenizer, step_token=\"\\n\\n\") \n",
    "    for p, full_resp in zip(gen_prompts, llm_outputs)\n",
    "]\n",
    "input_ids, steps, reward_flags = zip(*processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = prm_client.embeddings.create(\n",
    "                model=args[\"prm_path_rsd\"].split(\"/\")[-1],\n",
    "                input=input_ids,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data', [Embedding(embedding=[-0.59375, -0.4609375, 1.6015625, -1.515625, -0.515625, 1.125, -1.1796875, 1.1015625, 1.9609375, -0.11376953125, 0.13671875, 0.21484375, 0.7265625, -0.36328125, 0.306640625, -0.00640869140625, -0.423828125, -0.90625, 1.265625, 3.8125, 0.10595703125, -0.193359375, 0.97265625, -0.291015625, 0.1494140625, -1.09375, -0.53515625, -0.71875, -0.52734375, -0.12353515625, 0.404296875, -0.392578125, -0.50390625, -1.1484375, 0.3984375, -0.380859375, 0.6328125, 0.75390625, 0.8203125, -0.265625, 1.34375, 0.10107421875, -2.03125, -0.88671875, -0.33203125, 1.3515625, 0.5859375, 1.453125, 1.125, 0.2373046875, -1.3125, -1.2421875, -1.234375, 1.15625, 2.1875, -0.97265625, -2.6875, -0.1630859375, -2.015625, -2.15625, -0.765625, 0.216796875, -0.087890625, -0.337890625], index=0, object='embedding'), Embedding(embedding=[-0.59375, -0.4609375, -0.6640625, -0.984375, -0.2578125, -0.921875, 1.1171875, 2.078125, 3.8125, -1.515625, 0.205078125, -0.390625, -0.3984375, -1.4765625, 0.90234375, -2.890625, 2.15625, 0.2294921875, 1.34375, -0.6796875, -1.46875, -0.3203125, -0.8828125, -0.88671875, -0.333984375, 2.875, -1.375, 1.8671875, -0.6875, -0.6484375, 1.890625, 1.8046875, 1.609375, 0.353515625, 0.478515625, 2.9375, -0.26171875, 0.1728515625, 3.109375, -1.765625, 3.90625, 1.03125, 0.1875, 1.1953125, 1.75, 1.296875, 0.3984375, 0.33203125, 2.03125, -0.64453125, 0.3984375, 1.875, -1.875, 0.93359375, 1.453125, 0.11962890625, 0.162109375, 1.4296875, 0.2578125, -0.36328125, -0.0732421875, 2.140625, -0.486328125, -0.0732421875, -0.349609375, -0.490234375], index=1, object='embedding')])\n",
      "('model', 'Skywork-o1-Open-PRM-Qwen-2.5-1.5B')\n",
      "('object', 'list')\n",
      "('usage', Usage(prompt_tokens=130, total_tokens=130, completion_tokens=0, prompt_tokens_details=None))\n",
      "('id', 'embd-9cff88788af3469293e2814a3624e131')\n",
      "('created', 1313785)\n"
     ]
    }
   ],
   "source": [
    "for i in rewards:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(np.exp(-x) + 1)\n",
    "    \n",
    "def derive_step_rewards_vllm(raw_rewards, batch_reward_flags):\n",
    "    batch_step_rewards = []\n",
    "    for idx,data in enumerate(raw_rewards.data):\n",
    "        rewards = data.embedding\n",
    "        reward_flags = batch_reward_flags[idx]\n",
    "\n",
    "        step_rewards = [sigmoid(reward) for reward,flag in zip(rewards,reward_flags) if flag == 1]   \n",
    "        batch_step_rewards.append(step_rewards)\n",
    "    return batch_step_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.4780414772938761, 0.4163219602930174],\n",
       " [0.4134771498315425, 0.3798383564508293]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_rewards = derive_step_rewards_vllm(rewards, reward_flags)\n",
    "step_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
